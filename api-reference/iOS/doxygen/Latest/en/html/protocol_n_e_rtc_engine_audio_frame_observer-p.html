<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NERtc iOS SDK: &lt;NERtcEngineAudioFrameObserver&gt; Protocol Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">NERtc iOS SDK<span id="projectnumber">&#160;V4.6.10</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Instance Methods</a> &#124;
<a href="protocol_n_e_rtc_engine_audio_frame_observer-p-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">&lt;NERtcEngineAudioFrameObserver&gt; Protocol Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Returns the audio data <br  />
If you need to process audio data, you need to implement this protocol.  
 <a href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#details">More...</a></p>

<p><code>#import &lt;<a class="el" href="_n_e_rtc_engine_delegate_8h_source.html">NERtcEngineDelegate.h</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for &lt;NERtcEngineAudioFrameObserver&gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="protocol_n_e_rtc_engine_audio_frame_observer-p.png" alt=""/>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Instance Methods</h2></td></tr>
<tr class="memitem:a5dfe952459d840f86eb3851bf95666e0"><td class="memItemLeft" align="right" valign="top">(void)&#160;</td><td class="memItemRight" valign="bottom">- <a class="el" href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#a5dfe952459d840f86eb3851bf95666e0">onNERtcEngineAudioFrameDidRecord:</a></td></tr>
<tr class="memdesc:a5dfe952459d840f86eb3851bf95666e0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Occurs when the audio data is captured.  <a href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#a5dfe952459d840f86eb3851bf95666e0">More...</a><br /></td></tr>
<tr class="separator:a5dfe952459d840f86eb3851bf95666e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6de538aa534820f67b002ed1e8a84dc6"><td class="memItemLeft" align="right" valign="top">(void)&#160;</td><td class="memItemRight" valign="bottom">- <a class="el" href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#a6de538aa534820f67b002ed1e8a84dc6">onNERtcEngineAudioFrameWillPlayback:</a></td></tr>
<tr class="memdesc:a6de538aa534820f67b002ed1e8a84dc6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Occurs when the audio data is played back.  <a href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#a6de538aa534820f67b002ed1e8a84dc6">More...</a><br /></td></tr>
<tr class="separator:a6de538aa534820f67b002ed1e8a84dc6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e70fb2a067194a64c830bcc23b1d994"><td class="memItemLeft" align="right" valign="top">(void)&#160;</td><td class="memItemRight" valign="bottom">- <a class="el" href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#a6e70fb2a067194a64c830bcc23b1d994">onNERtcEnginePlaybackAudioFrameBeforeMixingWithUserID:frame:</a></td></tr>
<tr class="memdesc:a6e70fb2a067194a64c830bcc23b1d994"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the raw audio data of a specified remote user before audio mixing.  <a href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#a6e70fb2a067194a64c830bcc23b1d994">More...</a><br /></td></tr>
<tr class="separator:a6e70fb2a067194a64c830bcc23b1d994"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba6cf3b97efe66f4d712972e4c0c95e4"><td class="memItemLeft" align="right" valign="top">(void)&#160;</td><td class="memItemRight" valign="bottom">- <a class="el" href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#aba6cf3b97efe66f4d712972e4c0c95e4">onNERtcEnginePlaybackAudioFrameBeforeMixingWithUserID:frame:channelId:</a></td></tr>
<tr class="memdesc:aba6cf3b97efe66f4d712972e4c0c95e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the raw audio data of a specified remote user before audio mixing.  <a href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#aba6cf3b97efe66f4d712972e4c0c95e4">More...</a><br /></td></tr>
<tr class="separator:aba6cf3b97efe66f4d712972e4c0c95e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebbdb9feccf532c3bd8d464ba268ad6a"><td class="memItemLeft" align="right" valign="top">(void)&#160;</td><td class="memItemRight" valign="bottom">- <a class="el" href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#aebbdb9feccf532c3bd8d464ba268ad6a">onNERtcEngineMixedAudioFrame:</a></td></tr>
<tr class="memdesc:aebbdb9feccf532c3bd8d464ba268ad6a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the raw audio data of the local user and all remote users after mixing.  <a href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#aebbdb9feccf532c3bd8d464ba268ad6a">More...</a><br /></td></tr>
<tr class="separator:aebbdb9feccf532c3bd8d464ba268ad6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1f21fc239da61bc48f723428cb2be25"><td class="memItemLeft" align="right" valign="top">(void)&#160;</td><td class="memItemRight" valign="bottom">- <a class="el" href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#ae1f21fc239da61bc48f723428cb2be25">onNERtcEngineSubStreamAudioFrameDidRecord:</a></td></tr>
<tr class="memdesc:ae1f21fc239da61bc48f723428cb2be25"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the data of the local audio substream, used for the custom audio substream.  <a href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#ae1f21fc239da61bc48f723428cb2be25">More...</a><br /></td></tr>
<tr class="separator:ae1f21fc239da61bc48f723428cb2be25"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd2ca1af655a521455adb57b2da91c09"><td class="memItemLeft" align="right" valign="top">(void)&#160;</td><td class="memItemRight" valign="bottom">- <a class="el" href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#abd2ca1af655a521455adb57b2da91c09">onNERtcEnginePlaybackSubStreamAudioFrameBeforeMixingWithUserID:frame:channelId:</a></td></tr>
<tr class="memdesc:abd2ca1af655a521455adb57b2da91c09"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the audio substream data from a specified remote user before mixing audio.  <a href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#abd2ca1af655a521455adb57b2da91c09">More...</a><br /></td></tr>
<tr class="separator:abd2ca1af655a521455adb57b2da91c09"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >Returns the audio data <br  />
If you need to process audio data, you need to implement this protocol. </p>
</div><h2 class="groupheader">Method Documentation</h2>
<a id="a5dfe952459d840f86eb3851bf95666e0" name="a5dfe952459d840f86eb3851bf95666e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5dfe952459d840f86eb3851bf95666e0">&#9670;&nbsp;</a></span>onNERtcEngineAudioFrameDidRecord:</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">- (void) onNERtcEngineAudioFrameDidRecord: </td>
          <td></td>
          <td class="paramtype">(<a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a> *)&#160;</td>
          <td class="paramname"><em>frame</em></td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">optional</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Occurs when the audio data is captured. </p>
<p >The callback is used to process the audio data.</p><ul>
<li>The returned audio data has read and write permissions.</li>
<li>The callback is triggered when an operation is driven by the local audio data.</li>
<li>The callback returns synchronously, and the engine continues the audio processing flow. You cannot modify the content void *data points to in the frame and the format. If you want to modify the format, you can set the format by calling setParameter : kNERtcKeyObserveRecordAudioFrameFormat. <dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frame</td><td>The audio frame data. For more information, see <code><a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a></code>.   </td></tr>
  </table>
  </dd>
</dl>
</li>
</ul>

</div>
</div>
<a id="a6de538aa534820f67b002ed1e8a84dc6" name="a6de538aa534820f67b002ed1e8a84dc6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6de538aa534820f67b002ed1e8a84dc6">&#9670;&nbsp;</a></span>onNERtcEngineAudioFrameWillPlayback:</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">- (void) onNERtcEngineAudioFrameWillPlayback: </td>
          <td></td>
          <td class="paramtype">(<a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a> *)&#160;</td>
          <td class="paramname"><em>frame</em></td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">optional</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Occurs when the audio data is played back. </p>
<p >The callback is used to process the audio data.</p><ul>
<li>The callback returns synchronously, and the engine continues the audio processing flow.</li>
<li>The returned audio data has read and write permissions.</li>
<li>The callback is triggered when an operation is driven by the local audio data. <br  />
You cannot modify the content void *data points to in the frame and the format. If you want to modify the format, you can set the format by calling setParameter : kNERtcKeyObserveRecordAudioFrameFormat. <dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frame</td><td>The audio frame data. For more information, see <code><a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a></code>.   </td></tr>
  </table>
  </dd>
</dl>
</li>
</ul>

</div>
</div>
<a id="aebbdb9feccf532c3bd8d464ba268ad6a" name="aebbdb9feccf532c3bd8d464ba268ad6a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aebbdb9feccf532c3bd8d464ba268ad6a">&#9670;&nbsp;</a></span>onNERtcEngineMixedAudioFrame:</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">- (void) onNERtcEngineMixedAudioFrame: </td>
          <td></td>
          <td class="paramtype">(<a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a> *)&#160;</td>
          <td class="paramname"><em>frame</em></td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">optional</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the raw audio data of the local user and all remote users after mixing. </p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The callback is in read-only mode.</li>
<li>The returned audio data is read-only.</li>
<li>The callback is triggered when an operation is driven by the local audio data. You cannot modify the content that void *data points to in the frame and the format. If you need to modify the format, you can call setMixedAudioFrameParameters. </li>
</ul>
</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frame</td><td>The audio frame data. For more information, see <code><a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a></code>.   </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a6e70fb2a067194a64c830bcc23b1d994" name="a6e70fb2a067194a64c830bcc23b1d994"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6e70fb2a067194a64c830bcc23b1d994">&#9670;&nbsp;</a></span>onNERtcEnginePlaybackAudioFrameBeforeMixingWithUserID:frame:</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">- (void) onNERtcEnginePlaybackAudioFrameBeforeMixingWithUserID: </td>
          <td></td>
          <td class="paramtype">(uint64_t)&#160;</td>
          <td class="paramname"><em>userID</em></td>
        </tr>
        <tr>
          <td class="paramkey">frame:</td>
          <td></td>
          <td class="paramtype">(<a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a> *)&#160;</td>
          <td class="paramname"><em>frame</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td></td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">optional</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the raw audio data of a specified remote user before audio mixing. </p>
<p ><br  />
After the audio observer is registered, if the remote audio is subscribed by default and the remote user enables the audio, the SDK triggers this callback when the audio data before audio mixing is captured, and the audio data is returned to the user. </p><dl class="section note"><dt>Note</dt><dd><ul>
<li>The returned audio data is read-only.</li>
<li>You cannot modify the content that void *data pointed to in the frame and the format. </li>
</ul>
</dd></dl>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000002">Deprecated:</a></b></dt><dd>This API is about to be deprecated. Use <code><a class="el" href="protocol_n_e_rtc_engine_audio_frame_observer-p.html#aba6cf3b97efe66f4d712972e4c0c95e4">NERtcEngineAudioFrameObserver#onNERtcEnginePlaybackAudioFrameBeforeMixingWithUserID:frame:channelId:</a></code> instead. In multi-channel scenarios, channelId is used to identify different channels. </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">userID</td><td>The ID of a remote user. </td></tr>
    <tr><td class="paramname">frame</td><td>The audio frame data. For more information, see <code><a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a></code>.   </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aba6cf3b97efe66f4d712972e4c0c95e4" name="aba6cf3b97efe66f4d712972e4c0c95e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba6cf3b97efe66f4d712972e4c0c95e4">&#9670;&nbsp;</a></span>onNERtcEnginePlaybackAudioFrameBeforeMixingWithUserID:frame:channelId:</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">- (void) onNERtcEnginePlaybackAudioFrameBeforeMixingWithUserID: </td>
          <td></td>
          <td class="paramtype">(uint64_t)&#160;</td>
          <td class="paramname"><em>userID</em></td>
        </tr>
        <tr>
          <td class="paramkey">frame:</td>
          <td></td>
          <td class="paramtype">(<a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a> *)&#160;</td>
          <td class="paramname"><em>frame</em></td>
        </tr>
        <tr>
          <td class="paramkey">channelId:</td>
          <td></td>
          <td class="paramtype">(uint64_t)&#160;</td>
          <td class="paramname"><em>channelId</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td></td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">optional</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the raw audio data of a specified remote user before audio mixing. </p>
<p ><br  />
After the audio observer is registered, if the remote audio is subscribed by default and the remote user enables the audio, the SDK triggers this callback when the audio data before audio mixing is captured, and the audio data is returned to the user. </p><dl class="section note"><dt>Note</dt><dd><ul>
<li>The returned audio data is read-only.</li>
<li>You cannot modify the content that void *data pointed to in the frame and the format. </li>
</ul>
</dd></dl>
<dl class="section since"><dt>Since</dt><dd>V4.5.0 </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">userID</td><td>The ID of a remote user. </td></tr>
    <tr><td class="paramname">frame</td><td>The audio frame data. For more information, see <code><a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a></code>. </td></tr>
    <tr><td class="paramname">channelId</td><td>Channel ID. In multi-channel scenarios, channelId is used to identify different channels. <br  />
   </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="abd2ca1af655a521455adb57b2da91c09" name="abd2ca1af655a521455adb57b2da91c09"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd2ca1af655a521455adb57b2da91c09">&#9670;&nbsp;</a></span>onNERtcEnginePlaybackSubStreamAudioFrameBeforeMixingWithUserID:frame:channelId:</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">- (void) onNERtcEnginePlaybackSubStreamAudioFrameBeforeMixingWithUserID: </td>
          <td></td>
          <td class="paramtype">(uint64_t)&#160;</td>
          <td class="paramname"><em>userID</em></td>
        </tr>
        <tr>
          <td class="paramkey">frame:</td>
          <td></td>
          <td class="paramtype">(<a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a> *)&#160;</td>
          <td class="paramname"><em>frame</em></td>
        </tr>
        <tr>
          <td class="paramkey">channelId:</td>
          <td></td>
          <td class="paramtype">(uint64_t)&#160;</td>
          <td class="paramname"><em>channelId</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td></td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">optional</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the audio substream data from a specified remote user before mixing audio. </p>
<p ><br  />
After the audio observer is registered, the SDK will get the audio data from a specified remote user before mixing if the remote audio substream is subscribed to and the remote user publishes the audio substream. </p><dl class="section note"><dt>Note</dt><dd><ul>
<li>The returned audio data can only be read.</li>
<li>You are allowed to edit the content in void *data of a frameid *data but cannot edit the format. </li>
</ul>
</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">userID</td><td>A remote user ID. </td></tr>
    <tr><td class="paramname">frame</td><td>PCM audio frame data. For more information, see <code><a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a></code>. </td></tr>
    <tr><td class="paramname">channelId</td><td>Room ID. For multiple rooms, channelId is used to identify the rooms.   </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae1f21fc239da61bc48f723428cb2be25" name="ae1f21fc239da61bc48f723428cb2be25"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1f21fc239da61bc48f723428cb2be25">&#9670;&nbsp;</a></span>onNERtcEngineSubStreamAudioFrameDidRecord:</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">- (void) onNERtcEngineSubStreamAudioFrameDidRecord: </td>
          <td></td>
          <td class="paramtype">(<a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a> *)&#160;</td>
          <td class="paramname"><em>frame</em></td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">optional</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the data of the local audio substream, used for the custom audio substream. </p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>If the substream is enabled, the SDK will return the data.</li>
<li>The returned audio data supports the write or read modes. The callback is applied for custom audio substream. A write mode is recommended.</li>
<li>You are allowed to edit the content in void *data of a frameid *data but cannot edit the format. If you want to change the format, set the format by calling setParameter:kNERtcKeyObserveRecordAudioFrameFormat. </li>
</ul>
</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frame</td><td>PCM audio frame data. For more information, see <code><a class="el" href="interface_n_e_rtc_audio_frame.html">NERtcAudioFrame</a></code>.   </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this protocol was generated from the following file:<ul>
<li>exportHeaders/<a class="el" href="_n_e_rtc_engine_delegate_8h_source.html">NERtcEngineDelegate.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.4
</small></address>
</body>
</html>
